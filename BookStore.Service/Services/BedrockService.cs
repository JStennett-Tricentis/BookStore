using System.Diagnostics;
using System.Diagnostics.Metrics;
using System.Text;
using System.Text.Json;
using Amazon.BedrockRuntime;
using Amazon.BedrockRuntime.Model;
using BookStore.Common.Instrumentation;

namespace BookStore.Service.Services;

/// <summary>
/// Service for generating book summaries using AWS Bedrock (Claude via AWS).
/// </summary>
public class BedrockService : ILLMService
{
    private readonly AmazonBedrockRuntimeClient _client;
    private readonly ILogger<BedrockService> _logger;
    private readonly ActivitySource _activitySource;
    private readonly Counter<long> _inputTokensCounter;
    private readonly Counter<long> _outputTokensCounter;
    private readonly Counter<long> _totalTokensCounter;
    private readonly Histogram<double> _costHistogram;
    private readonly string _model;

    public string ProviderName => "bedrock";

    public BedrockService(
        IConfiguration configuration,
        ILogger<BedrockService> logger,
        ActivitySource activitySource,
        IMeterFactory meterFactory)
    {
        var region = configuration["LLM:Providers:Bedrock:Region"] ?? configuration["Bedrock:Region"] ?? "us-east-1";
        _model = configuration["LLM:Providers:Bedrock:Model"] ?? configuration["Bedrock:Model"] ?? "anthropic.claude-3-5-sonnet-20241022-v2:0";
        _client = new AmazonBedrockRuntimeClient(Amazon.RegionEndpoint.GetBySystemName(region));
        _logger = logger;
        _activitySource = activitySource;

        var meter = meterFactory.Create("BookStore.Service.Bedrock");

        _inputTokensCounter = meter.CreateCounter<long>(
            "bedrock.tokens.input",
            unit: "tokens",
            description: "Number of input tokens consumed by AWS Bedrock");

        _outputTokensCounter = meter.CreateCounter<long>(
            "bedrock.tokens.output",
            unit: "tokens",
            description: "Number of output tokens generated by AWS Bedrock");

        _totalTokensCounter = meter.CreateCounter<long>(
            "bedrock.tokens.total",
            unit: "tokens",
            description: "Total number of tokens (input + output) used by AWS Bedrock");

        _costHistogram = meter.CreateHistogram<double>(
            "bedrock.cost.usd",
            unit: "USD",
            description: "Estimated cost per request in USD");
    }

    public async Task<string> GenerateBookSummaryAsync(
        string title,
        string author,
        string? description,
        CancellationToken cancellationToken = default)
    {
        using var activity = _activitySource.StartActivity("bedrock.generate_summary", ActivityKind.Client);

        var prompt = BuildPrompt(title, author, description);

        activity?.SetTag(TraceTags.LlmRequestTypeKey, TraceTags.ChatRequestType);
        activity?.SetTag(TraceTags.LlmOperationNameKey, TraceTags.ChatOperation);
        activity?.SetTag(TraceTags.GenAiOperationNameKey, TraceTags.ChatOperation);
        activity?.SetTag(TraceTags.LLMSystem, "bedrock");
        activity?.SetTag(TraceTags.LlmModelNameKey, _model);
        activity?.SetTag(TraceTags.GenAiRequestMaxTokensKey, 500);
        activity?.SetTag(TraceTags.LlmPrompt0ContentKey, prompt);
        activity?.SetTag(TraceTags.LlmPrompt0RoleKey, "user");

        var startTime = DateTimeOffset.UtcNow;

        try
        {
            var requestBody = new
            {
                anthropic_version = "bedrock-2023-05-31",
                max_tokens = 500,
                temperature = 0.7,
                messages = new[]
                {
                    new
                    {
                        role = "user",
                        content = prompt
                    }
                }
            };

            var requestBodyJson = JsonSerializer.Serialize(requestBody);

            var request = new InvokeModelRequest
            {
                ModelId = _model,
                Body = new MemoryStream(Encoding.UTF8.GetBytes(requestBodyJson)),
                ContentType = "application/json",
                Accept = "application/json"
            };

            var response = await _client.InvokeModelAsync(request, cancellationToken);

            var latency = (DateTimeOffset.UtcNow - startTime).TotalMilliseconds;

            using var reader = new StreamReader(response.Body);
            var responseBody = await reader.ReadToEndAsync(cancellationToken);
            var responseJson = JsonDocument.Parse(responseBody);

            var summary = responseJson.RootElement.GetProperty("content")[0].GetProperty("text").GetString() ?? "Unable to generate summary";
            var stopReason = responseJson.RootElement.GetProperty("stop_reason").GetString();
            var usage = responseJson.RootElement.GetProperty("usage");
            var inputTokens = usage.GetProperty("input_tokens").GetInt32();
            var outputTokens = usage.GetProperty("output_tokens").GetInt32();
            var totalTokens = inputTokens + outputTokens;

            // Calculate cost based on Claude 3.5 Sonnet via Bedrock pricing
            // Input: $3 per million tokens, Output: $15 per million tokens
            var inputCost = (inputTokens / 1_000_000.0) * 3.0;
            var outputCost = (outputTokens / 1_000_000.0) * 15.0;
            var totalCost = inputCost + outputCost;

            _inputTokensCounter.Add(inputTokens, new KeyValuePair<string, object?>("model", _model));
            _outputTokensCounter.Add(outputTokens, new KeyValuePair<string, object?>("model", _model));
            _totalTokensCounter.Add(totalTokens, new KeyValuePair<string, object?>("model", _model));
            _costHistogram.Record(totalCost, new KeyValuePair<string, object?>("model", _model));

            activity?.SetTag(TraceTags.GenAiResponseModelKey, _model);
            activity?.SetTag(TraceTags.GenAiUsageInputTokensKey, inputTokens);
            activity?.SetTag(TraceTags.GenAiUsageOutputTokensKey, outputTokens);
            activity?.SetTag(TraceTags.GenAiUsageTotalTokensKey, totalTokens);
            activity?.SetTag(TraceTags.LlmLatencyKey, latency);
            activity?.SetTag(TraceTags.LlmCompletion0ContentKey, summary);
            activity?.SetTag(TraceTags.LlmCompletion0RoleKey, "assistant");
            activity?.SetTag(TraceTags.LlmCompletion0FinishReasonKey, stopReason ?? "end_turn");
            activity?.SetTag(TraceTags.TraceLoopOutputKey, summary);
            activity?.SetTag("gen_ai.cost.usd", totalCost);
            activity?.SetStatus(ActivityStatusCode.Ok);

            _logger.LogInformation(
                "Generated book summary using AWS Bedrock. Model: {Model}, Input tokens: {InputTokens}, Output tokens: {OutputTokens}, Cost: ${Cost:F6}, Latency: {Latency}ms",
                _model, inputTokens, outputTokens, totalCost, latency);

            return summary;
        }
        catch (Exception ex)
        {
            activity?.SetStatus(ActivityStatusCode.Error, ex.Message);
            activity?.AddTag("exception.type", ex.GetType().FullName);
            activity?.AddTag("exception.message", ex.Message);
            _logger.LogError(ex, "Failed to generate book summary using AWS Bedrock");
            throw;
        }
    }

    private static string BuildPrompt(string title, string author, string? description)
    {
        var prompt = $"Generate a concise, engaging 2-3 sentence summary for a book titled \"{title}\" by {author}.";

        if (!string.IsNullOrEmpty(description))
        {
            prompt += $" Here's some context about the book: {description}";
        }

        prompt += " Focus on what makes this book interesting and worth reading.";

        return prompt;
    }
}
