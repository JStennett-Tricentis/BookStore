# Project Structure Guide

## ğŸ“ Where Everything Lives

```
BookStore/
â”œâ”€â”€ ğŸ“– README.md                          # Quick start guide
â”œâ”€â”€ ğŸ“– CLAUDE.md                          # Complete project documentation
â”œâ”€â”€ ğŸ”§ Makefile                           # All automation commands (see MAKEFILE_REFERENCE.md)
â”‚
â”œâ”€â”€ ğŸ“š docs/                              # ğŸ“– READ THESE FIRST
â”‚   â”œâ”€â”€ LLM_PROVIDER_GUIDE.md            # â­ How to use Ollama/LM Studio/Claude/OpenAI
â”‚   â”œâ”€â”€ MAKEFILE_REFERENCE.md            # â­ Complete Makefile command guide
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md             # â­ This file
â”‚   â”œâ”€â”€ MIGRATION_TO_HUB_SERVICES.md     # Migration guide for production
â”‚   â””â”€â”€ MIGRATION_CHECKLIST.md           # Phase 1 checklist
â”‚
â”œâ”€â”€ ğŸ¯ BookStore.Service/                 # Main API Service
â”‚   â”œâ”€â”€ appsettings.json                 # âš™ï¸ PRIMARY CONFIG FILE
â”‚   â”œâ”€â”€ appsettings.Development.json     # Dev overrides (optional)
â”‚   â”œâ”€â”€ appsettings.example.json         # Template for new users
â”‚   â”œâ”€â”€ Program.cs                       # Service startup & DI
â”‚   â”œâ”€â”€ Controllers/                     # API endpoints
â”‚   â”‚   â”œâ”€â”€ BooksController.cs          # CRUD + AI summary endpoint
â”‚   â”‚   â”œâ”€â”€ AuthorsController.cs        # Author management
â”‚   â”‚   â””â”€â”€ ErrorTestController.cs      # Error testing endpoints
â”‚   â””â”€â”€ Services/                        # Business logic
â”‚       â”œâ”€â”€ ILLMService.cs              # Common LLM interface
â”‚       â”œâ”€â”€ ILLMServiceFactory.cs       # Provider selection
â”‚       â”œâ”€â”€ OllamaService.cs            # Ollama integration
â”‚       â”œâ”€â”€ LMStudioService.cs          # LM Studio integration â­ NEW
â”‚       â”œâ”€â”€ ClaudeService.cs            # Claude integration
â”‚       â”œâ”€â”€ OpenAIService.cs            # OpenAI integration
â”‚       â”œâ”€â”€ BedrockService.cs           # AWS Bedrock integration
â”‚       â”œâ”€â”€ BookService.cs              # Book business logic
â”‚       â””â”€â”€ AuthorService.cs            # Author business logic
â”‚
â”œâ”€â”€ ğŸ¯ BookStore.Performance.Service/     # K6 Test Orchestration
â”‚   â”œâ”€â”€ appsettings.json                 # Performance service config
â”‚   â”œâ”€â”€ Controllers/                     # API to trigger tests
â”‚   â””â”€â”€ wwwroot/                         # ğŸŒ Web UI Dashboard
â”‚       â”œâ”€â”€ index.html                   # Performance testing dashboard
â”‚       â””â”€â”€ README.md                    # Dashboard documentation
â”‚
â”œâ”€â”€ ğŸ¯ BookStore.Aspire.AppHost/          # .NET Aspire Orchestration
â”‚   â”œâ”€â”€ Program.cs                       # Orchestration setup
â”‚   â””â”€â”€ appsettings.json                 # Aspire config (API Simulator toggle)
â”‚
â”œâ”€â”€ ğŸ“¦ BookStore.Common/                  # Shared models
â”‚   â””â”€â”€ Models/                          # Book, Author DTOs
â”‚
â”œâ”€â”€ ğŸ“¦ BookStore.Common.Instrumentation/  # OpenTelemetry Setup
â”‚   â””â”€â”€ OpenTelemetryExtensions.cs       # OTel configuration
â”‚
â”œâ”€â”€ ğŸ§ª BookStore.Service.Tests.Integration/ # .NET Integration Tests
â”‚   â””â”€â”€ Tests/                           # API integration tests
â”‚
â”œâ”€â”€ ğŸ§ª BookStore.Performance.Tests/       # K6 Load Tests
â”‚   â”œâ”€â”€ scenarios/                       # ğŸ¯ Test scenarios
â”‚   â”‚   â”œâ”€â”€ smoke-test.js               # Quick 2-min test
â”‚   â”‚   â”œâ”€â”€ load-test.js                # 10-user, 10-min
â”‚   â”‚   â”œâ”€â”€ stress-test.js              # 30-user, 15-min
â”‚   â”‚   â”œâ”€â”€ spike-test.js               # Burst to 50 users
â”‚   â”‚   â”œâ”€â”€ chaos-test.js               # Random spikes + errors + LLM
â”‚   â”‚   â”œâ”€â”€ extreme-chaos-test.js       # ğŸ”¥ 500+ users (WILL BREAK)
â”‚   â”‚   â”œâ”€â”€ ai-load.js                  # AI-focused load test
â”‚   â”‚   â”œâ”€â”€ ai-stress.js                # AI stress test
â”‚   â”‚   â””â”€â”€ mixed-workload.js           # CRUD + AI mix
â”‚   â”œâ”€â”€ tests/                           # Individual endpoint tests
â”‚   â”‚   â”œâ”€â”€ books.js                    # Book CRUD tests
â”‚   â”‚   â”œâ”€â”€ authors.js                  # Author tests
â”‚   â”‚   â”œâ”€â”€ errors.js                   # Error handling tests
â”‚   â”‚   â””â”€â”€ ai-summary.js               # AI summary tests
â”‚   â”œâ”€â”€ utils/                           # Test utilities
â”‚   â””â”€â”€ config/                          # Test configuration
â”‚
â”œâ”€â”€ ğŸ“Š monitoring/                        # Monitoring Configuration
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus.yml              # Prometheus config
â”‚   â””â”€â”€ grafana/
â”‚       â”œâ”€â”€ dashboards/                 # 10 Grafana dashboards (91 widgets)
â”‚       â”‚   â”œâ”€â”€ bookstore-performance.json
â”‚       â”‚   â”œâ”€â”€ bookstore-errors.json
â”‚       â”‚   â”œâ”€â”€ bookstore-llm-metrics.json
â”‚       â”‚   â”œâ”€â”€ bookstore-dotnet-runtime.json
â”‚       â”‚   â”œâ”€â”€ bookstore-http-kestrel.json
â”‚       â”‚   â”œâ”€â”€ bookstore-threading.json
â”‚       â”‚   â”œâ”€â”€ bookstore-dependencies.json
â”‚       â”‚   â”œâ”€â”€ bookstore-system-health.json
â”‚       â”‚   â”œâ”€â”€ bookstore-demo.json     # 53 curated panels
â”‚       â”‚   â””â”€â”€ bookstore-mega.json     # All 91 widgets
â”‚       â””â”€â”€ *.py                        # Dashboard generation scripts
â”‚
â””â”€â”€ ğŸ§ª tests/                             # Other Tests
    â””â”€â”€ postman/                         # Postman/Newman smoke tests

```

---

## âš™ï¸ Configuration Files (What To Edit)

### Primary Configuration: `BookStore.Service/appsettings.json`

**This is the main file you edit for:**
- âœ… LLM Provider selection (`LLM.Provider`)
- âœ… Provider API keys and models (`LLM.Providers.{Provider}`)
- âœ… MongoDB connection (`Database.ConnectionString`)
- âœ… Redis connection (`Redis.ConnectionString`)
- âœ… OpenTelemetry settings (`Telemetry`)

**Example:**
```json
{
  "LLM": {
    "Provider": "LMStudio",  // â­ Change this to switch providers
    "Providers": {
      "Ollama": {
        "Url": "http://localhost:11434",
        "Model": "gemma3:1b",
        "Enabled": true
      },
      "LMStudio": {
        "Url": "http://localhost:1234",
        "Model": "lmstudio-community/Phi-3.1-mini-4k-instruct-GGUF",
        "Enabled": true
      },
      "Claude": {
        "ApiKey": "sk-ant-...",  // â­ Add your key here
        "Model": "claude-3-5-sonnet-20241022",
        "Enabled": true
      }
    }
  }
}
```

### Other Configuration Files

| File | Purpose | When To Edit |
|------|---------|-------------|
| `BookStore.Service/appsettings.Development.json` | Dev-specific overrides | Optional, only if you need different dev settings |
| `BookStore.Service/appsettings.example.json` | Template for new users | Never edit, use as reference |
| `BookStore.Aspire.AppHost/appsettings.json` | Aspire orchestration | Only to enable/disable API Simulator |
| `BookStore.Performance.Service/appsettings.json` | Performance service | Rarely (K6 Docker settings) |
| `monitoring/prometheus/prometheus.yml` | Prometheus scraping | Rarely (add new metrics) |

---

## ğŸ¯ Quick Task Guide

### "I want to test with a different LLM provider"

1. Edit: `BookStore.Service/appsettings.json`
2. Change: `"Provider": "Ollama"` to `"Provider": "LMStudio"` (or Claude, OpenAI, Bedrock)
3. Restart: `make run-aspire`
4. Test: `make perf-ai-smoke`

**See:** [docs/LLM_PROVIDER_GUIDE.md](LLM_PROVIDER_GUIDE.md)

---

### "I want to run a quick performance test"

```bash
make perf-smoke        # 2 min, basic test
make perf-ai-smoke     # 3 min, AI endpoints
```

**See:** [docs/MAKEFILE_REFERENCE.md](MAKEFILE_REFERENCE.md)

---

### "I want to see live metrics during a test"

```bash
make perf-workspace    # Opens Dashboard + Grafana + Aspire
# Then click "Start Test" in Dashboard
# Switch to Grafana tab to watch metrics
```

---

### "I want to add a new LLM provider"

1. Create: `BookStore.Service/Services/MyProviderService.cs`
   - Implement `ILLMService`
   - Add token counting and metrics
2. Register: `BookStore.Service/Program.cs`
   - Add `builder.Services.AddSingleton<MyProviderService>()`
   - Add case in switch statement
3. Configure: `BookStore.Service/appsettings.json`
   - Add section in `LLM.Providers.MyProvider`
4. Update: `BookStore.Service/Services/ILLMServiceFactory.cs`
   - Add provider to factory

**Example:** See `LMStudioService.cs` for reference implementation

---

### "I want to add a new K6 test scenario"

1. Create: `BookStore.Performance.Tests/scenarios/my-test.js`
2. Add Makefile target: `Makefile`
   ```makefile
   perf-my-test:
       cd BookStore.Performance.Tests && k6 run scenarios/my-test.js
   ```
3. Test: `make perf-my-test`

**Templates:** See `scenarios/smoke-test.js` for a simple example

---

### "I want to add a new Grafana dashboard"

1. Create: `monitoring/grafana/dashboards/my-dashboard.json`
2. Export from Grafana UI or use Python scripts:
   ```bash
   cd monitoring/grafana
   python3 generate_demo_dashboard.py  # As reference
   ```
3. Access via Grafana UI at http://localhost:3333

---

### "I want to understand what a Makefile command does"

```bash
make help              # List all commands
cat Makefile           # Read the source
```

**Or see:** [docs/MAKEFILE_REFERENCE.md](MAKEFILE_REFERENCE.md)

---

## ğŸ“ Common File Locations Cheat Sheet

| What You Need | Where It Lives |
|---------------|---------------|
| **Change LLM provider** | `BookStore.Service/appsettings.json` |
| **Add API key** | `BookStore.Service/appsettings.json` |
| **View API endpoints** | `BookStore.Service/Controllers/*.cs` |
| **LLM integration code** | `BookStore.Service/Services/*Service.cs` |
| **Run quick test** | `make perf-smoke` |
| **View metrics** | `make grafana-mega` |
| **K6 test scenarios** | `BookStore.Performance.Tests/scenarios/*.js` |
| **Grafana dashboards** | `monitoring/grafana/dashboards/*.json` |
| **OpenTelemetry setup** | `BookStore.Common.Instrumentation/` |
| **Integration tests** | `BookStore.Service.Tests.Integration/` |
| **Makefile commands** | `Makefile` or [MAKEFILE_REFERENCE.md](MAKEFILE_REFERENCE.md) |
| **Complete docs** | `CLAUDE.md` |

---

## ğŸ” Finding Things

### "Where is the LLM integration code?"
- `BookStore.Service/Services/` - All LLM provider implementations
- `BookStore.Service/Controllers/BooksController.cs` - `/generate-summary` endpoint

### "Where are the performance tests?"
- `BookStore.Performance.Tests/scenarios/` - Test scenarios
- `BookStore.Performance.Tests/tests/` - Individual endpoint tests

### "Where is the monitoring configuration?"
- `monitoring/prometheus/prometheus.yml` - Prometheus config
- `monitoring/grafana/dashboards/` - All 10 Grafana dashboards

### "Where is the Aspire orchestration?"
- `BookStore.Aspire.AppHost/Program.cs` - Orchestration logic
- Starts: MongoDB, Redis, Prometheus, Grafana, API, Performance Service

### "Where are the OpenTelemetry metrics defined?"
- `BookStore.Common.Instrumentation/` - OTel setup
- Individual service files - Custom metrics (e.g., `OllamaService.cs`)

---

## ğŸš€ Quick Start Paths

### Path 1: Just Run It
```bash
make run-aspire      # Start everything
make perf-smoke      # Run test
make grafana-mega    # View metrics
```

### Path 2: Performance Testing Focus
```bash
make run-aspire           # Start services
make perf-workspace       # Open workspace (3 tabs)
# Click "Start Test" in Dashboard tab
# Watch metrics in Grafana tab
```

### Path 3: LLM Provider Comparison
```bash
# Setup Ollama
ollama pull gemma3:1b
# Edit appsettings.json: Provider = "Ollama"
make run-aspire
make perf-ai-smoke

# Setup LM Studio
# Download from lmstudio.ai, load model, start server
# Edit appsettings.json: Provider = "LMStudio"
make restart
make perf-ai-smoke

# Compare metrics in Grafana
make grafana-mega
```

### Path 4: Development Workflow
```bash
make run-aspire              # Start services
make swagger                 # Test API manually
make test-integration        # Run .NET tests
make perf-load               # Run load test
make grafana-mega            # View metrics
```

---

## ğŸ“š Documentation Hierarchy

1. **README.md** - 30-second overview
2. **This file** - Where everything lives
3. **[MAKEFILE_REFERENCE.md](MAKEFILE_REFERENCE.md)** - All commands
4. **[LLM_PROVIDER_GUIDE.md](LLM_PROVIDER_GUIDE.md)** - LLM setup & testing
5. **CLAUDE.md** - Complete technical documentation

---

## ğŸ’¡ Key Principles

- **Single source of truth**: `BookStore.Service/appsettings.json`
- **One command to rule them all**: `make run-aspire`
- **Web UI for everything**: Dashboard, Grafana, Aspire, Swagger
- **Zero-cost testing**: Use Ollama or LM Studio
- **Real-time visibility**: All metrics â†’ Grafana automatically
